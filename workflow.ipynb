{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.data_helper import load_data\n",
    "import torch\n",
    "\n",
    "images_train, poses_train, int_mat = load_data(\"bottles\",\"train\", 1)\n",
    "images_val, poses_val, _ = load_data(\"bottles\",\"val\", 1)\n",
    "\n",
    "images_train = torch.cat([images_train, images_val[1:23],images_val[24:39],images_val[40:44],images_val[45:]], axis=0)\n",
    "poses_train = torch.cat([poses_train, poses_val[1:23], poses_val[24:39], poses_val[40:44],poses_val[45:]], axis=0)\n",
    "images_train.shape, poses_train.shape\n",
    "# _, poses_test, _ = load_data(\"./bottles\", \"test\")\n",
    "images_train.shape, poses_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.nerf_helper import get_rays\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "rays_o_list, rays_d_list = [],[]\n",
    "\n",
    "for pose in tqdm(poses_train):\n",
    "    rays_o, rays_d = get_rays((800,800),int_mat, pose)\n",
    "    rays_o_list.append(rays_o)\n",
    "    rays_d_list.append(rays_d)\n",
    "\n",
    "rays_o_list, rays_d_list = torch.stack(rays_o_list), torch.stack(rays_d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rays_o_list = torch.flatten(rays_o_list, start_dim=0, end_dim=2)\n",
    "rays_d_list = torch.flatten(rays_d_list, start_dim=0, end_dim=2)\n",
    "rays_d_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "images_train = torch.flatten(images_train, start_dim=0, end_dim=2)\n",
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.eq(images_train,1.)\n",
    "mask = mask[:,0]*mask[:,1]*mask[:,2]\n",
    "mask = torch.nonzero(mask==False).squeeze()\n",
    "len(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stage 1: training SingleNeRF with Data Argumentation\n",
    "'''\n",
    "\n",
    "from nerf.model import NeRF\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# define all the paremeters here\n",
    "N_pos = 10\n",
    "N_dir = 4\n",
    "N_sample = 256\n",
    "N_importance = 128\n",
    "batch_size = 1024*48\n",
    "fc_width = 258\n",
    "fc_depth = 8\n",
    "skips = [4]\n",
    "lr = 5e-4\n",
    "num_it = 10001\n",
    "val_idx = 1\n",
    "val_gap = 1000\n",
    "threshold = (0,5)\n",
    "checkpoint_path_coarse = \"NERF_STAGE1.pt\"\n",
    "checkpoint_path_fine = \"whatever\"\n",
    "psnrs = []\n",
    "val_iters = []\n",
    "losses = []\n",
    "mini_batch = 1\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nerf_coarse = torch.nn.DataParallel(NeRF(6*N_pos, 6*N_dir,skips, fc_depth, fc_width)).to(device)\n",
    "nerf_fine = None\n",
    "\n",
    "if nerf_fine:\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(nerf_coarse.parameters())+list(nerf_fine.parameters()),lr=lr)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(nerf_coarse.parameters(),lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.9, step_size=1000)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=1000, eta_min=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.train import train_sampled\n",
    "\n",
    "train_sampled(\n",
    "    nerf_coarse=nerf_coarse, # coarse model\n",
    "    nerf_fine=nerf_fine, # fine model\n",
    "    optimizer=optimizer, # set optimizer\n",
    "    scheduler=scheduler, # set scheduler\n",
    "    imgs_train=torch.cat([images_train,images_train[mask]],dim=0), # flattened training set with argumentation\n",
    "    rays_o_list=torch.cat([rays_o_list, rays_o_list[mask]],dim=0), # flattened rays_o with argumentation\n",
    "    rays_d_list=torch.cat([rays_d_list, rays_d_list[mask]],dim=0), # flattened rays_d with argumentation\n",
    "    imgs_val=images_val,\n",
    "    poses_val=poses_val,\n",
    "    val_idx=val_idx,\n",
    "    int_mat=int_mat,\n",
    "    threshold=threshold,\n",
    "    N_pos=N_pos,\n",
    "    N_dir=N_dir,\n",
    "    N_sample=N_sample,\n",
    "    N_importance=N_importance,\n",
    "    checkpoint_path_coarse=checkpoint_path_coarse,\n",
    "    checkpoint_path_fine=checkpoint_path_fine,\n",
    "    batch_size=batch_size,\n",
    "    psnrs = psnrs,\n",
    "    val_iters = val_iters,\n",
    "    losses = losses,\n",
    "    epochs = num_it,\n",
    "    val_gap = val_gap,\n",
    "    mini_batch=mini_batch,\n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stage 2: training SingleNeRF without Data Argumentation\n",
    "'''\n",
    "\n",
    "from nerf.model import NeRF\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# define all the paremeters here\n",
    "N_pos = 10\n",
    "N_dir = 4\n",
    "N_sample = 256\n",
    "N_importance = 128\n",
    "batch_size = 1024*48\n",
    "fc_width = 258\n",
    "fc_depth = 8\n",
    "skips = [4]\n",
    "lr = 5e-4\n",
    "num_it = 10001\n",
    "val_idx = 1\n",
    "val_gap = 1000\n",
    "threshold = (0,5)\n",
    "checkpoint_path_coarse = \"NERF_STAGE2.pt\"\n",
    "checkpoint_path_fine = \"whatever\"\n",
    "psnrs = []\n",
    "val_iters = []\n",
    "losses = []\n",
    "mini_batch = 1\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if nerf_fine:\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(nerf_coarse.parameters())+list(nerf_fine.parameters()),lr=lr)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(nerf_coarse.parameters(),lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.9, step_size=1000)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=1000, eta_min=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampled(\n",
    "    nerf_coarse=nerf_coarse, # coarse model\n",
    "    nerf_fine=nerf_fine, # fine model\n",
    "    optimizer=optimizer, # set optimizer\n",
    "    scheduler=scheduler, # set scheduler\n",
    "    imgs_train=images_train, # flattened training set\n",
    "    rays_o_list=rays_o_list, # flattened rays_o\n",
    "    rays_d_list=rays_d_list, # flattened rays_d\n",
    "    imgs_val=images_val,\n",
    "    poses_val=poses_val,\n",
    "    val_idx=val_idx,\n",
    "    int_mat=int_mat,\n",
    "    threshold=threshold,\n",
    "    N_pos=N_pos,\n",
    "    N_dir=N_dir,\n",
    "    N_sample=N_sample,\n",
    "    N_importance=N_importance,\n",
    "    checkpoint_path_coarse=checkpoint_path_coarse,\n",
    "    checkpoint_path_fine=checkpoint_path_fine,\n",
    "    batch_size=batch_size,\n",
    "    psnrs = psnrs,\n",
    "    val_iters = val_iters,\n",
    "    losses = losses,\n",
    "    epochs = num_it,\n",
    "    val_gap = val_gap,\n",
    "    mini_batch=mini_batch,\n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stage 3: hard copy single NeRF and construct DouleNeRF to train\n",
    "'''\n",
    "from nerf.model import NeRF\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# define all the paremeters here\n",
    "N_pos = 10\n",
    "N_dir = 4\n",
    "N_sample = 96\n",
    "N_importance = 128\n",
    "batch_size = 1024*32\n",
    "fc_width = 258\n",
    "fc_depth = 8\n",
    "skips = [4]\n",
    "lr = 1e-4\n",
    "num_it = 20001\n",
    "val_idx = 1\n",
    "val_gap = 1000\n",
    "threshold = (0,5)\n",
    "checkpoint_path_coarse = \"NERF_STAGE3_COARSE.pt\"\n",
    "checkpoint_path_fine = \"NERF_STAGE3_FINE.pt\"\n",
    "psnrs= []\n",
    "val_iters = []\n",
    "losses= []\n",
    "mini_batch = 1\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nerf_coarse = torch.nn.DataParallel(NeRF(6*N_pos, 6*N_dir,skips, fc_depth, fc_width)).to(device)\n",
    "nerf_fine = torch.nn.DataParallel(NeRF(6*N_pos, 6*N_dir,skips, fc_depth, fc_width)).to(device)\n",
    "\n",
    "nerf_coarse.load_state_dict(torch.load('NERF_STAGE2.pt')['model_state_dict'])\n",
    "\n",
    "# hard copy the saved singleNeRF\n",
    "nerf_fine.load_state_dict(torch.load('NERF_STAGE2.pt')['model_state_dict'])\n",
    "\n",
    "if nerf_fine:\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(nerf_coarse.parameters())+list(nerf_fine.parameters()),lr=lr)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(nerf_coarse.parameters(),lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.9, step_size=1000)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=1000, eta_min=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampled(\n",
    "    nerf_coarse=nerf_coarse, # coarse model\n",
    "    nerf_fine=nerf_fine, # fine model\n",
    "    optimizer=optimizer, # set optimizer\n",
    "    scheduler=scheduler, # set scheduler\n",
    "    imgs_train=images_train, # flattened training set with ehencement\n",
    "    rays_o_list=rays_o_list, # flattened rays_o\n",
    "    rays_d_list=rays_d_list, # flattened rays_d\n",
    "    imgs_val=images_val,\n",
    "    poses_val=poses_val,\n",
    "    val_idx=val_idx,\n",
    "    int_mat=int_mat,\n",
    "    threshold=threshold,\n",
    "    N_pos=N_pos,\n",
    "    N_dir=N_dir,\n",
    "    N_sample=N_sample,\n",
    "    N_importance=N_importance,\n",
    "    checkpoint_path_coarse=checkpoint_path_coarse,\n",
    "    checkpoint_path_fine=checkpoint_path_fine,\n",
    "    batch_size=batch_size,\n",
    "    psnrs = psnrs,\n",
    "    val_iters = val_iters,\n",
    "    losses = losses,\n",
    "    epochs = num_it,\n",
    "    val_gap = val_gap,\n",
    "    mini_batch=mini_batch,\n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stage 4: finetune\n",
    "'''\n",
    "from nerf.model import NeRF\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# define all the paremeters here\n",
    "N_pos = 10\n",
    "N_dir = 4\n",
    "N_sample = 256\n",
    "N_importance = 96\n",
    "batch_size = 1024*32\n",
    "fc_width = 258\n",
    "fc_depth = 8\n",
    "skips = [4]\n",
    "lr = 1e-5\n",
    "num_it = 30001\n",
    "val_idx = 1\n",
    "val_gap = 2000\n",
    "threshold = (0,5)\n",
    "checkpoint_path_coarse = \"NERF_STAGE4_COARSE.pt\"\n",
    "checkpoint_path_fine = \"NERF_STAGE4_FINE.pt\"\n",
    "psnrs = []\n",
    "val_iters = []\n",
    "losses = []\n",
    "mini_batch = 1\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if nerf_fine:\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(nerf_coarse.parameters())+list(nerf_fine.parameters()),lr=lr)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(nerf_coarse.parameters(),lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampled(\n",
    "    nerf_coarse=nerf_coarse, # coarse model\n",
    "    nerf_fine=nerf_fine, # fine model\n",
    "    optimizer=optimizer, # set optimizer\n",
    "    scheduler=scheduler, # set scheduler\n",
    "    imgs_train=images_train, # flattened training set\n",
    "    rays_o_list=rays_o_list, # flattened rays_o\n",
    "    rays_d_list=rays_d_list, # flattened rays_d\n",
    "    imgs_val=images_val,\n",
    "    poses_val=poses_val,\n",
    "    val_idx=val_idx,\n",
    "    int_mat=int_mat,\n",
    "    threshold=threshold,\n",
    "    N_pos=N_pos,\n",
    "    N_dir=N_dir,\n",
    "    N_sample=N_sample,\n",
    "    N_importance=N_importance,\n",
    "    checkpoint_path_coarse=checkpoint_path_coarse,\n",
    "    checkpoint_path_fine=checkpoint_path_fine,\n",
    "    batch_size=batch_size,\n",
    "    psnrs = psnrs,\n",
    "    val_iters = val_iters,\n",
    "    losses = losses,\n",
    "    epochs = num_it,\n",
    "    val_gap = val_gap,\n",
    "    mini_batch=mini_batch,\n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.nerf_helper import nerf_step_sampled\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# images_val, poses_val, _ = load_data(\"bottles\",\"val\", 1)\n",
    "_, poses_test, _ = load_data(\"./bottles\", \"test\")\n",
    "idxs = [23,39,44] \n",
    "for idx in idxs:\n",
    "    with torch.no_grad():\n",
    "        rays_o, rays_d = get_rays((800,800), int_mat.cpu(), poses_val[idx])\n",
    "\n",
    "        pred_rgb = torch.zeros((800,800,3)).to(device)\n",
    "        # pred_depth = torch.zeros((800,800)).to(device)\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                sub_rays_o = rays_o[i*200:(i*200)+200,j*200:(j*200)+200,:].to(device)\n",
    "                sub_rays_d = rays_d[i*200:(i*200)+200,j*200:(j*200)+200,:].to(device)\n",
    "\n",
    "                h,w = 200,200\n",
    "\n",
    "                _, fine_out = nerf_step_sampled(\n",
    "                    nerf_coarse,\n",
    "                    nerf_fine,\n",
    "                    (h,w),\n",
    "                    sub_rays_o,\n",
    "                    sub_rays_d,\n",
    "                    threshold,\n",
    "                    device,\n",
    "                    True,\n",
    "                    True,\n",
    "                    N_pos,\n",
    "                    N_dir,\n",
    "                    N_sample,\n",
    "                    N_importance,\n",
    "                    batch_size\n",
    "                )\n",
    "\n",
    "                pred_rgb[i*200:(i*200)+200,j*200:(j*200)+200,:] = fine_out[0]\n",
    "                # pred_depth[i*200:(i*200)+200,j*200:(j*200)+200] = fine_out[1]\n",
    "        l = F.mse_loss(pred_rgb, images_val[idx].to(device))\n",
    "        psnr = -10.*torch.log10(l)\n",
    "        print(f'psnr of {idx}:', psnr)\n",
    "        im = Image.fromarray((np.round(pred_rgb.cpu().numpy()*255)).astype(np.uint8)).convert('RGB')\n",
    "        im.save(f\"val_pred/final_stage/{idx}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('3dml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11b5c4d2e22cff6e2bbabc735b0308f9d508ebbcc0e1d5beb4feea159aaaeb65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
